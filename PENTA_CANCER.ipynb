{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PENTA_CANCER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACsObgcnEanZ",
        "outputId": "7d8fdd8d-9c43-486c-cf65-9e59feba4303"
      },
      "source": [
        "!git clone https://github.com/myproject-01/penta_cancer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'penta_cancer'...\n",
            "remote: Enumerating objects: 1676, done.\u001b[K\n",
            "remote: Counting objects: 100% (1676/1676), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1495/1495), done.\u001b[K\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPQE4Te4BbhR",
        "outputId": "8c697b4b-f5ce-4bb4-8ca2-ed882582d133"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi4r5e3Icje5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvqHtoJ-EZS1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmc3hjwlM95B"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.keras.optimizer_v2 import optimizer_v2\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import gen_resource_variable_ops\n",
        "from tensorflow.python.training import gen_training_ops\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dgIwkAtPUHI"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "class ImageToArrayPreprocessor:\n",
        "\tdef __init__(self, dataFormat=None):\n",
        "\t\t# store the image data format\n",
        "\t\tself.dataFormat = dataFormat\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# apply the Keras utility function that correctly rearranges\n",
        "\t\t# the dimensions of the image\n",
        "\t\treturn img_to_array(image, data_format=self.dataFormat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71R4O5EPUPe"
      },
      "source": [
        "# import the necessary packages\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "class AspectAwarePreprocessor:\n",
        "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "\t\t# store the target image width, height, and interpolation\n",
        "\t\t# method used when resizing\n",
        "\t\tself.width = width\n",
        "\t\tself.height = height\n",
        "\t\tself.inter = inter\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# grab the dimensions of the image and then initialize\n",
        "\t\t# the deltas to use when cropping\n",
        "\t\t(h, w) = image.shape[:2]\n",
        "\t\tdW = 0\n",
        "\t\tdH = 0\n",
        "\n",
        "\t\t# if the width is smaller than the height, then resize\n",
        "\t\t# along the width (i.e., the smaller dimension) and then\n",
        "\t\t# update the deltas to crop the height to the desired\n",
        "\t\t# dimension\n",
        "\t\tif w < h:\n",
        "\t\t\timage = imutils.resize(image, width=self.width,\n",
        "\t\t\t\tinter=self.inter)\n",
        "\t\t\tdH = int((image.shape[0] - self.height) / 2.0)\n",
        "\n",
        "\t\t# otherwise, the height is smaller than the width so\n",
        "\t\t# resize along the height and then update the deltas\n",
        "\t\t# crop along the width\n",
        "\t\telse:\n",
        "\t\t\timage = imutils.resize(image, height=self.height,\n",
        "\t\t\t\tinter=self.inter)\n",
        "\t\t\tdW = int((image.shape[1] - self.width) / 2.0)\n",
        "\n",
        "\t\t# now that our images have been resized, we need to\n",
        "\t\t# re-grab the width and height, followed by performing\n",
        "\t\t# the crop\n",
        "\t\t(h, w) = image.shape[:2]\n",
        "\t\timage = image[dH:h - dH, dW:w - dW]\n",
        "\n",
        "\t\t# finally, resize the image to the provided spatial\n",
        "\t\t# dimensions to ensure our output image is always a fixed\n",
        "\t\t# size\n",
        "\t\treturn cv2.resize(image, (self.width, self.height),\n",
        "\t\t\tinterpolation=self.inter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvYKwDbBM-Ax"
      },
      "source": [
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgVQDMMotrA0"
      },
      "source": [
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.keras.optimizer_v2 import optimizer_v2\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import gen_resource_variable_ops\n",
        "from tensorflow.python.training import gen_training_ops\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "\n",
        "class SGD(optimizer_v2.OptimizerV2):\n",
        " \n",
        "  _HAS_AGGREGATE_GRAD = True\n",
        "\n",
        "  def __init__(self,\n",
        "               learning_rate=0.01,\n",
        "               momentum=0.0,\n",
        "               nesterov=False,\n",
        "               name=\"SGD\",\n",
        "               **kwargs):\n",
        "    super(SGD, self).__init__(name, **kwargs)\n",
        "    self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate))\n",
        "    self._set_hyper(\"decay\", self._initial_decay)\n",
        "\n",
        "    self._momentum = False\n",
        "    if isinstance(momentum, ops.Tensor) or callable(momentum) or momentum > 0:\n",
        "      self._momentum = True\n",
        "    if isinstance(momentum, (int, float)) and (momentum < 0 or momentum > 1):\n",
        "      raise ValueError(\"`momentum` must be between [0, 1].\")\n",
        "    self._set_hyper(\"momentum\", momentum)\n",
        "\n",
        "    self.nesterov = nesterov\n",
        "\n",
        "  def _create_slots(self, var_list):\n",
        "    if self._momentum:\n",
        "      for var in var_list:\n",
        "        self.add_slot(var, \"momentum\")\n",
        "\n",
        "  def _prepare_local(self, var_device, var_dtype, apply_state):\n",
        "    super(SGD, self)._prepare_local(var_device, var_dtype, apply_state)\n",
        "    apply_state[(var_device, var_dtype)][\"momentum\"] = array_ops.identity(\n",
        "        self._get_hyper(\"momentum\", var_dtype))\n",
        "\n",
        "  def _resource_apply_dense(self, grad, var, apply_state=None):\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = ((apply_state or {}).get((var_device, var_dtype))\n",
        "                    or self._fallback_apply_state(var_device, var_dtype))\n",
        "\n",
        "    if self._momentum:\n",
        "      momentum_var = self.get_slot(var, \"momentum\")\n",
        "      return gen_training_ops.ResourceApplyKerasMomentum(\n",
        "          var=var.handle,\n",
        "          accum=momentum_var.handle,\n",
        "          lr=coefficients[\"lr_t\"],\n",
        "          grad=grad,\n",
        "          momentum=coefficients[\"momentum\"],\n",
        "          use_locking=self._use_locking,\n",
        "          use_nesterov=self.nesterov)\n",
        "    else:\n",
        "      return gen_training_ops.ResourceApplyGradientDescent(\n",
        "          var=var.handle,\n",
        "          alpha=coefficients[\"lr_t\"],\n",
        "          delta=grad,\n",
        "          use_locking=self._use_locking)\n",
        "\n",
        "  def _resource_apply_sparse_duplicate_indices(self, grad, var, indices,\n",
        "                                               **kwargs):\n",
        "    if self._momentum:\n",
        "      return super(SGD, self)._resource_apply_sparse_duplicate_indices(\n",
        "          grad, var, indices, **kwargs)\n",
        "    else:\n",
        "      var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "      coefficients = (kwargs.get(\"apply_state\", {}).get((var_device, var_dtype))\n",
        "                      or self._fallback_apply_state(var_device, var_dtype))\n",
        "\n",
        "      return gen_resource_variable_ops.ResourceScatterAdd(\n",
        "          resource=var.handle,\n",
        "          indices=indices,\n",
        "          updates=-grad * coefficients[\"lr_t\"])\n",
        "\n",
        "  def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
        "    # This method is only needed for momentum optimization.\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = ((apply_state or {}).get((var_device, var_dtype))\n",
        "                    or self._fallback_apply_state(var_device, var_dtype))\n",
        "\n",
        "    momentum_var = self.get_slot(var, \"momentum\")\n",
        "    return gen_training_ops.ResourceSparseApplyKerasMomentum(\n",
        "        var=var.handle,\n",
        "        accum=momentum_var.handle,\n",
        "        lr=coefficients[\"lr_t\"],\n",
        "        grad=grad,\n",
        "        indices=indices,\n",
        "        momentum=coefficients[\"momentum\"],\n",
        "        use_locking=self._use_locking,\n",
        "        use_nesterov=self.nesterov)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(SGD, self).get_config()\n",
        "    config.update({\n",
        "        \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
        "        \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
        "        \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
        "        \"nesterov\": self.nesterov,\n",
        "    })\n",
        "    return config\n",
        "\n",
        "\n",
        "from tensorflow.python.eager import def_function\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.keras import backend_config\n",
        "from tensorflow.python.keras.optimizer_v2 import optimizer_v2\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import state_ops\n",
        "from tensorflow.python.training import gen_training_ops\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "\n",
        "class Adam(optimizer_v2.OptimizerV2):\n",
        " \n",
        "\n",
        "  _HAS_AGGREGATE_GRAD = True\n",
        "\n",
        "  def __init__(self,\n",
        "               learning_rate=0.001,\n",
        "               beta_1=0.9,\n",
        "               beta_2=0.999,\n",
        "               epsilon=1e-7,\n",
        "               amsgrad=False,\n",
        "               name='Adam',\n",
        "               **kwargs):\n",
        "    super(Adam, self).__init__(name, **kwargs)\n",
        "    self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))\n",
        "    self._set_hyper('decay', self._initial_decay)\n",
        "    self._set_hyper('beta_1', beta_1)\n",
        "    self._set_hyper('beta_2', beta_2)\n",
        "    self.epsilon = epsilon or backend_config.epsilon()\n",
        "    self.amsgrad = amsgrad\n",
        "\n",
        "  def _create_slots(self, var_list):\n",
        "    # Create slots for the first and second moments.\n",
        "    # Separate for-loops to respect the ordering of slot variables from v1.\n",
        "    for var in var_list:\n",
        "      self.add_slot(var, 'm')\n",
        "    for var in var_list:\n",
        "      self.add_slot(var, 'v')\n",
        "    if self.amsgrad:\n",
        "      for var in var_list:\n",
        "        self.add_slot(var, 'vhat')\n",
        "\n",
        "  def _prepare_local(self, var_device, var_dtype, apply_state):\n",
        "    super(Adam, self)._prepare_local(var_device, var_dtype, apply_state)\n",
        "\n",
        "    local_step = math_ops.cast(self.iterations + 1, var_dtype)\n",
        "    beta_1_t = array_ops.identity(self._get_hyper('beta_1', var_dtype))\n",
        "    beta_2_t = array_ops.identity(self._get_hyper('beta_2', var_dtype))\n",
        "    beta_1_power = math_ops.pow(beta_1_t, local_step)\n",
        "    beta_2_power = math_ops.pow(beta_2_t, local_step)\n",
        "    lr = (apply_state[(var_device, var_dtype)]['lr_t'] *\n",
        "          (math_ops.sqrt(1 - beta_2_power) / (1 - beta_1_power)))\n",
        "    apply_state[(var_device, var_dtype)].update(\n",
        "        dict(\n",
        "            lr=lr,\n",
        "            epsilon=ops.convert_to_tensor_v2_with_dispatch(\n",
        "                self.epsilon, var_dtype),\n",
        "            beta_1_t=beta_1_t,\n",
        "            beta_1_power=beta_1_power,\n",
        "            one_minus_beta_1_t=1 - beta_1_t,\n",
        "            beta_2_t=beta_2_t,\n",
        "            beta_2_power=beta_2_power,\n",
        "            one_minus_beta_2_t=1 - beta_2_t))\n",
        "\n",
        "  def set_weights(self, weights):\n",
        "    params = self.weights\n",
        "    # If the weights are generated by Keras V1 optimizer, it includes vhats\n",
        "    # even without amsgrad, i.e, V1 optimizer has 3x + 1 variables, while V2\n",
        "    # optimizer has 2x + 1 variables. Filter vhats out for compatibility.\n",
        "    num_vars = int((len(params) - 1) / 2)\n",
        "    if len(weights) == 3 * num_vars + 1:\n",
        "      weights = weights[:len(params)]\n",
        "    super(Adam, self).set_weights(weights)\n",
        "\n",
        "  def _resource_apply_dense(self, grad, var, apply_state=None):\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = ((apply_state or {}).get((var_device, var_dtype))\n",
        "                    or self._fallback_apply_state(var_device, var_dtype))\n",
        "\n",
        "    m = self.get_slot(var, 'm')\n",
        "    v = self.get_slot(var, 'v')\n",
        "\n",
        "    if not self.amsgrad:\n",
        "      return gen_training_ops.ResourceApplyAdam(\n",
        "          var=var.handle,\n",
        "          m=m.handle,\n",
        "          v=v.handle,\n",
        "          beta1_power=coefficients['beta_1_power'],\n",
        "          beta2_power=coefficients['beta_2_power'],\n",
        "          lr=coefficients['lr_t'],\n",
        "          beta1=coefficients['beta_1_t'],\n",
        "          beta2=coefficients['beta_2_t'],\n",
        "          epsilon=coefficients['epsilon'],\n",
        "          grad=grad,\n",
        "          use_locking=self._use_locking)\n",
        "    else:\n",
        "      vhat = self.get_slot(var, 'vhat')\n",
        "      return gen_training_ops.ResourceApplyAdamWithAmsgrad(\n",
        "          var=var.handle,\n",
        "          m=m.handle,\n",
        "          v=v.handle,\n",
        "          vhat=vhat.handle,\n",
        "          beta1_power=coefficients['beta_1_power'],\n",
        "          beta2_power=coefficients['beta_2_power'],\n",
        "          lr=coefficients['lr_t'],\n",
        "          beta1=coefficients['beta_1_t'],\n",
        "          beta2=coefficients['beta_2_t'],\n",
        "          epsilon=coefficients['epsilon'],\n",
        "          grad=grad,\n",
        "          use_locking=self._use_locking)\n",
        "\n",
        "  def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = ((apply_state or {}).get((var_device, var_dtype))\n",
        "                    or self._fallback_apply_state(var_device, var_dtype))\n",
        "\n",
        "    # m_t = beta1 * m + (1 - beta1) * g_t\n",
        "    m = self.get_slot(var, 'm')\n",
        "    m_scaled_g_values = grad * coefficients['one_minus_beta_1_t']\n",
        "    m_t = state_ops.assign(m, m * coefficients['beta_1_t'],\n",
        "                           use_locking=self._use_locking)\n",
        "    with ops.control_dependencies([m_t]):\n",
        "      m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)\n",
        "\n",
        "    # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
        "    v = self.get_slot(var, 'v')\n",
        "    v_scaled_g_values = (grad * grad) * coefficients['one_minus_beta_2_t']\n",
        "    v_t = state_ops.assign(v, v * coefficients['beta_2_t'],\n",
        "                           use_locking=self._use_locking)\n",
        "    with ops.control_dependencies([v_t]):\n",
        "      v_t = self._resource_scatter_add(v, indices, v_scaled_g_values)\n",
        "\n",
        "    if not self.amsgrad:\n",
        "      v_sqrt = math_ops.sqrt(v_t)\n",
        "      var_update = state_ops.assign_sub(\n",
        "          var, coefficients['lr'] * m_t / (v_sqrt + coefficients['epsilon']),\n",
        "          use_locking=self._use_locking)\n",
        "      return control_flow_ops.group(*[var_update, m_t, v_t])\n",
        "    else:\n",
        "      v_hat = self.get_slot(var, 'vhat')\n",
        "      v_hat_t = math_ops.maximum(v_hat, v_t)\n",
        "      with ops.control_dependencies([v_hat_t]):\n",
        "        v_hat_t = state_ops.assign(\n",
        "            v_hat, v_hat_t, use_locking=self._use_locking)\n",
        "      v_hat_sqrt = math_ops.sqrt(v_hat_t)\n",
        "      var_update = state_ops.assign_sub(\n",
        "          var,\n",
        "          coefficients['lr'] * m_t / (v_hat_sqrt + coefficients['epsilon']),\n",
        "          use_locking=self._use_locking)\n",
        "      return control_flow_ops.group(*[var_update, m_t, v_t, v_hat_t])\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(Adam, self).get_config()\n",
        "    config.update({\n",
        "        'learning_rate': self._serialize_hyperparameter('learning_rate'),\n",
        "        'decay': self._serialize_hyperparameter('decay'),\n",
        "        'beta_1': self._serialize_hyperparameter('beta_1'),\n",
        "        'beta_2': self._serialize_hyperparameter('beta_2'),\n",
        "        'epsilon': self.epsilon,\n",
        "        'amsgrad': self.amsgrad,\n",
        "    })\n",
        "    return config\n",
        "\n",
        "\n",
        "class NonFusedAdam(optimizer_v2.OptimizerV2):\n",
        "\n",
        "\n",
        "  _HAS_AGGREGATE_GRAD = True\n",
        "\n",
        "  def __init__(self,\n",
        "               learning_rate=0.001,\n",
        "               beta_1=0.9,\n",
        "               beta_2=0.999,\n",
        "               epsilon=1e-7,\n",
        "               amsgrad=False,\n",
        "               name='Adam',\n",
        "               **kwargs):\n",
        "   \n",
        "    super(NonFusedAdam, self).__init__(name, **kwargs)\n",
        "    self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))\n",
        "    self._set_hyper('decay', self._initial_decay)\n",
        "    self._set_hyper('beta_1', beta_1)\n",
        "    self._set_hyper('beta_2', beta_2)\n",
        "    self.epsilon = epsilon or backend_config.epsilon()\n",
        "    self.amsgrad = amsgrad\n",
        "\n",
        "  def _create_slots(self, var_list):\n",
        "    # Create slots for the first and second moments.\n",
        "    # Separate for-loops to respect the ordering of slot variables from v1.\n",
        "    for var in var_list:\n",
        "      self.add_slot(var, 'm')\n",
        "    for var in var_list:\n",
        "      self.add_slot(var, 'v')\n",
        "    if self.amsgrad:\n",
        "      for var in var_list:\n",
        "        self.add_slot(var, 'vhat')\n",
        "\n",
        "  def _prepare_local(self, var_device, var_dtype, apply_state):\n",
        "    super(NonFusedAdam, self)._prepare_local(var_device, var_dtype, apply_state)\n",
        "\n",
        "    local_step = math_ops.cast(self.iterations + 1, var_dtype)\n",
        "    beta_1_t = array_ops.identity(self._get_hyper('beta_1', var_dtype))\n",
        "    beta_2_t = array_ops.identity(self._get_hyper('beta_2', var_dtype))\n",
        "    beta_1_power = math_ops.pow(beta_1_t, local_step)\n",
        "    beta_2_power = math_ops.pow(beta_2_t, local_step)\n",
        "    lr = (\n",
        "        apply_state[(var_device, var_dtype)]['lr_t'] *\n",
        "        (math_ops.sqrt(1 - beta_2_power) / (1 - beta_1_power)))\n",
        "    apply_state[(var_device, var_dtype)].update(\n",
        "        dict(\n",
        "            lr=lr,\n",
        "            epsilon=ops.convert_to_tensor_v2_with_dispatch(\n",
        "                self.epsilon, var_dtype),\n",
        "            beta_1_t=beta_1_t,\n",
        "            beta_1_power=beta_1_power,\n",
        "            one_minus_beta_1_t=1 - beta_1_t,\n",
        "            beta_2_t=beta_2_t,\n",
        "            beta_2_power=beta_2_power,\n",
        "            one_minus_beta_2_t=1 - beta_2_t))\n",
        "\n",
        "  def set_weights(self, weights):\n",
        "    params = self.weights\n",
        "    # If the weights are generated by Keras V1 optimizer, it includes vhats\n",
        "    # even without amsgrad, i.e, V1 optimizer has 3x + 1 variables, while V2\n",
        "    # optimizer has 2x + 1 variables. Filter vhats out for compatibility.\n",
        "    num_vars = int((len(params) - 1) / 2)\n",
        "    if len(weights) == 3 * num_vars + 1:\n",
        "      weights = weights[:len(params)]\n",
        "    super(NonFusedAdam, self).set_weights(weights)\n",
        "\n",
        "  @def_function.function(experimental_compile=True)\n",
        "  def _resource_apply_dense(self, grad, var, apply_state=None):\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = ((apply_state or {}).get((var_device, var_dtype)) or\n",
        "                    self._fallback_apply_state(var_device, var_dtype))\n",
        "\n",
        "    m = self.get_slot(var, 'm')\n",
        "    v = self.get_slot(var, 'v')\n",
        "\n",
        "    alpha = (\n",
        "        coefficients['lr_t'] * math_ops.sqrt(1 - coefficients['beta_2_power']) /\n",
        "        (1 - coefficients['beta_1_power']))\n",
        "    m.assign_add((grad - m) * (1 - coefficients['beta_1_t']))\n",
        "    v.assign_add((math_ops.square(grad) - v) * (1 - coefficients['beta_2_t']))\n",
        "    if self.amsgrad:\n",
        "      vhat = self.get_slot(var, 'vhat')\n",
        "      vhat.assign(math_ops.maximum(vhat, v))\n",
        "      v = vhat\n",
        "    var.assign_sub(\n",
        "        (m * alpha) / (math_ops.sqrt(v) - coefficients['epsilon']))\n",
        "\n",
        "  @def_function.function(experimental_compile=True)\n",
        "  def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
        "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
        "    coefficients = ((apply_state or {}).get((var_device, var_dtype)) or\n",
        "                    self._fallback_apply_state(var_device, var_dtype))\n",
        "\n",
        "    # m_t = beta1 * m + (1 - beta1) * g_t\n",
        "    m = self.get_slot(var, 'm')\n",
        "    m_scaled_g_values = grad * coefficients['one_minus_beta_1_t']\n",
        "    m.assign(m * coefficients['beta_1_t'])\n",
        "    m.scatter_add(ops.IndexedSlices(m_scaled_g_values, indices))\n",
        "\n",
        "    # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
        "    v = self.get_slot(var, 'v')\n",
        "    v_scaled_g_values = (grad * grad) * coefficients['one_minus_beta_2_t']\n",
        "    v.assign(v * coefficients['beta_2_t'])\n",
        "    v.scatter_add(ops.IndexedSlices(v_scaled_g_values, indices))\n",
        "\n",
        "    if not self.amsgrad:\n",
        "      var.assign_sub(coefficients['lr'] * m /\n",
        "                     (math_ops.sqrt(v) + coefficients['epsilon']))\n",
        "    else:\n",
        "      v_hat = self.get_slot(var, 'vhat')\n",
        "      v_hat.assign(math_ops.maximum(v_hat, v))\n",
        "      var.assign_sub(coefficients['lr'] * m /\n",
        "                     (math_ops.sqrt(v_hat) + coefficients['epsilon']))\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(NonFusedAdam, self).get_config()\n",
        "    config.update({\n",
        "        'learning_rate': self._serialize_hyperparameter('learning_rate'),\n",
        "        'decay': self._serialize_hyperparameter('decay'),\n",
        "        'beta_1': self._serialize_hyperparameter('beta_1'),\n",
        "        'beta_2': self._serialize_hyperparameter('beta_2'),\n",
        "        'epsilon': self.epsilon,\n",
        "        'amsgrad': self.amsgrad,\n",
        "    })\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSNHH2y2KJid"
      },
      "source": [
        "\n",
        " \n",
        "class VGG16:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "\n",
        "\t\t# first CONV => RELU => CONV => RELU => POOL layer set\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(512))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-4yXgt9RKYS"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class SimpleDatasetLoader:\n",
        "\tdef __init__(self, preprocessors=None):\n",
        "\t\t# store the image preprocessor\n",
        "\t\tself.preprocessors = preprocessors\n",
        "\n",
        "\t\t# if the preprocessors are None, initialize them as an\n",
        "\t\t# empty list\n",
        "\t\tif self.preprocessors is None:\n",
        "\t\t\tself.preprocessors = []\n",
        "\n",
        "\tdef load(self, imagePaths, verbose=-1):\n",
        "\t\t# initialize the list of features and labels\n",
        "\t\tdata = []\n",
        "\t\tlabels = []\n",
        "\n",
        "\t\t# loop over the input images\n",
        "\t\tfor (i, imagePath) in enumerate(imagePaths):\n",
        "\t\t\t# load the image and extract the class label assuming\n",
        "\t\t\t# that our path has the following format:\n",
        "\t\t\t# /path/to/dataset/{class}/{image}.jpg\n",
        "\t\t\timage = cv2.imread(imagePath)\n",
        "\t\t\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t\t\t# check to see if our preprocessors are not None\n",
        "\t\t\tif self.preprocessors is not None:\n",
        "\t\t\t\t# loop over the preprocessors and apply each to\n",
        "\t\t\t\t# the image\n",
        "\t\t\t\tfor p in self.preprocessors:\n",
        "\t\t\t\t\timage = p.preprocess(image)\n",
        "\n",
        "\t\t\t# treat our processed image as a \"feature vector\"\n",
        "\t\t\t# by updating the data list followed by the labels\n",
        "\t\t\tdata.append(image)\n",
        "\t\t\tlabels.append(label)\n",
        "\n",
        "\t\t\t# show an update every `verbose` images\n",
        "\t\t\tif verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
        "\t\t\t\tprint(\"[INFO] processed {}/{}\".format(i + 1,\n",
        "\t\t\t\t\tlen(imagePaths)))\n",
        "\n",
        "\t\t# return a tuple of the data and labels\n",
        "\t\treturn (np.array(data), np.array(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SlESW-WQpEm",
        "outputId": "fadda544-0dfd-4ce8-cbe0-6bbc964e1699"
      },
      "source": [
        "# grab the list of images that we'll be describing, then extract\n",
        "# the class label names from the image paths\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(\"drive/MyDrive/penta_dataset/\"))\n",
        "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
        "classNames = [str(x) for x in np.unique(classNames)]\n",
        "\n",
        "# initialize the image preprocessors\n",
        "aap = AspectAwarePreprocessor(224, 224)\n",
        "iap = ImageToArrayPreprocessor()\n",
        "\n",
        "# load the dataset from disk then scale the raw pixel intensities to\n",
        "# the range [0, 1]\n",
        "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
        "(data, labels) = sdl.load(imagePaths, verbose=100)\n",
        "data = data.astype(\"float\") / 255.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] processed 100/2863\n",
            "[INFO] processed 200/2863\n",
            "[INFO] processed 300/2863\n",
            "[INFO] processed 400/2863\n",
            "[INFO] processed 500/2863\n",
            "[INFO] processed 600/2863\n",
            "[INFO] processed 700/2863\n",
            "[INFO] processed 800/2863\n",
            "[INFO] processed 900/2863\n",
            "[INFO] processed 1000/2863\n",
            "[INFO] processed 1100/2863\n",
            "[INFO] processed 1200/2863\n",
            "[INFO] processed 1300/2863\n",
            "[INFO] processed 1400/2863\n",
            "[INFO] processed 1500/2863\n",
            "[INFO] processed 1600/2863\n",
            "[INFO] processed 1700/2863\n",
            "[INFO] processed 1800/2863\n",
            "[INFO] processed 1900/2863\n",
            "[INFO] processed 2000/2863\n",
            "[INFO] processed 2100/2863\n",
            "[INFO] processed 2200/2863\n",
            "[INFO] processed 2300/2863\n",
            "[INFO] processed 2400/2863\n",
            "[INFO] processed 2500/2863\n",
            "[INFO] processed 2600/2863\n",
            "[INFO] processed 2700/2863\n",
            "[INFO] processed 2800/2863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMdAAVEbM-HQ"
      },
      "source": [
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.25, random_state=42)\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MBh0T0fgM-No",
        "outputId": "56a0dba3-2470-4e09-ce04-7f244eccbb48"
      },
      "source": [
        "model = VGG16.build(224,224, 3, 11)\n",
        "\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "print(\"[INFO] training head...\")\n",
        "model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
        "\tvalidation_data=(testX, testY), epochs=20,\n",
        "\tsteps_per_epoch=len(trainX) // 32, verbose=1)\n",
        "\n",
        "# evaluate the network after initialization\n",
        "print(\"[INFO] evaluating after initialization...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=classNames))\n",
        "print(\"[INFO] re-compiling model...\")\n",
        "opt = SGD(lr=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "print(\"[INFO] fine-tuning model...\")\n",
        "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
        "\tvalidation_data=(testX, testY), epochs=20,\n",
        "\tsteps_per_epoch=len(trainX) // 32, verbose=1)\n",
        "\n",
        "for key in H.history.keys():\n",
        "    print(key)\n",
        "# evaluate the network on the fine-tuned model\n",
        "print(\"[INFO] evaluating after fine-tuning...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=classNames))\n",
        "\n",
        "\n",
        "# save the model to disk\n",
        "print(\"[INFO] serializing model...\")\n",
        "model.save(\"output.model\")\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on penta cancer\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(\"output.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training head...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "67/67 [==============================] - 66s 509ms/step - loss: 1.6822 - accuracy: 0.5603 - val_loss: 6.7599 - val_accuracy: 0.1187\n",
            "Epoch 2/20\n",
            "67/67 [==============================] - 32s 480ms/step - loss: 0.8196 - accuracy: 0.7047 - val_loss: 7.4289 - val_accuracy: 0.2137\n",
            "Epoch 3/20\n",
            "67/67 [==============================] - 32s 480ms/step - loss: 0.7128 - accuracy: 0.7493 - val_loss: 6.0396 - val_accuracy: 0.2556\n",
            "Epoch 4/20\n",
            "67/67 [==============================] - 32s 488ms/step - loss: 0.5849 - accuracy: 0.7888 - val_loss: 5.8158 - val_accuracy: 0.2472\n",
            "Epoch 5/20\n",
            "67/67 [==============================] - 32s 477ms/step - loss: 0.4759 - accuracy: 0.8200 - val_loss: 6.3775 - val_accuracy: 0.2891\n",
            "Epoch 6/20\n",
            "67/67 [==============================] - 32s 481ms/step - loss: 0.5110 - accuracy: 0.8237 - val_loss: 4.6267 - val_accuracy: 0.2975\n",
            "Epoch 7/20\n",
            "67/67 [==============================] - 32s 479ms/step - loss: 0.4458 - accuracy: 0.8274 - val_loss: 1.4159 - val_accuracy: 0.6047\n",
            "Epoch 8/20\n",
            "67/67 [==============================] - 32s 482ms/step - loss: 0.3709 - accuracy: 0.8614 - val_loss: 2.1901 - val_accuracy: 0.5293\n",
            "Epoch 9/20\n",
            "67/67 [==============================] - 32s 477ms/step - loss: 0.4084 - accuracy: 0.8454 - val_loss: 0.8065 - val_accuracy: 0.6788\n",
            "Epoch 10/20\n",
            "67/67 [==============================] - 32s 478ms/step - loss: 0.3604 - accuracy: 0.8524 - val_loss: 0.4598 - val_accuracy: 0.8170\n",
            "Epoch 11/20\n",
            "67/67 [==============================] - 32s 480ms/step - loss: 0.3782 - accuracy: 0.8507 - val_loss: 0.9113 - val_accuracy: 0.7556\n",
            "Epoch 12/20\n",
            "67/67 [==============================] - 32s 479ms/step - loss: 0.4206 - accuracy: 0.8415 - val_loss: 0.7309 - val_accuracy: 0.8031\n",
            "Epoch 13/20\n",
            "67/67 [==============================] - 32s 479ms/step - loss: 0.3641 - accuracy: 0.8522 - val_loss: 0.2565 - val_accuracy: 0.9008\n",
            "Epoch 14/20\n",
            "67/67 [==============================] - 32s 480ms/step - loss: 0.3229 - accuracy: 0.8644 - val_loss: 0.3210 - val_accuracy: 0.8603\n",
            "Epoch 15/20\n",
            "67/67 [==============================] - 32s 481ms/step - loss: 0.3086 - accuracy: 0.8692 - val_loss: 0.6392 - val_accuracy: 0.7668\n",
            "Epoch 16/20\n",
            "67/67 [==============================] - 32s 477ms/step - loss: 0.4550 - accuracy: 0.8356 - val_loss: 0.6406 - val_accuracy: 0.7751\n",
            "Epoch 17/20\n",
            "67/67 [==============================] - 32s 477ms/step - loss: 0.3370 - accuracy: 0.8685 - val_loss: 0.7254 - val_accuracy: 0.7346\n",
            "Epoch 18/20\n",
            "67/67 [==============================] - 32s 479ms/step - loss: 0.3158 - accuracy: 0.8737 - val_loss: 0.7644 - val_accuracy: 0.7291\n",
            "Epoch 19/20\n",
            "67/67 [==============================] - 32s 478ms/step - loss: 0.3617 - accuracy: 0.8591 - val_loss: 1.1158 - val_accuracy: 0.7011\n",
            "Epoch 20/20\n",
            "67/67 [==============================] - 32s 478ms/step - loss: 0.3682 - accuracy: 0.8478 - val_loss: 2.5679 - val_accuracy: 0.5223\n",
            "[INFO] evaluating after initialization...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   brain_normal       0.33      1.00      0.50        19\n",
            "   brain_tumour       1.00      0.10      0.18        31\n",
            "  breast_cancer       0.65      0.84      0.73        56\n",
            "  breast_normal       0.66      0.53      0.59       199\n",
            "cervical_cancer       0.00      0.00      0.00        57\n",
            "cervical_normal       0.88      0.69      0.77        52\n",
            "         ignore       0.31      0.95      0.47        87\n",
            "    lung_cancer       0.50      0.01      0.02        87\n",
            "    lung_normal       0.67      0.94      0.78        83\n",
            " thyroid_cancer       1.00      0.04      0.07        26\n",
            " thyroid_normal       1.00      0.05      0.10        19\n",
            "\n",
            "       accuracy                           0.52       716\n",
            "      macro avg       0.64      0.47      0.38       716\n",
            "   weighted avg       0.59      0.52      0.45       716\n",
            "\n",
            "[INFO] re-compiling model...\n",
            "[INFO] fine-tuning model...\n",
            "Epoch 1/20\n",
            "67/67 [==============================] - 33s 481ms/step - loss: 0.3456 - accuracy: 0.8722 - val_loss: 0.7161 - val_accuracy: 0.7360\n",
            "Epoch 2/20\n",
            "67/67 [==============================] - 32s 475ms/step - loss: 0.3083 - accuracy: 0.8835 - val_loss: 0.3967 - val_accuracy: 0.8268\n",
            "Epoch 3/20\n",
            "67/67 [==============================] - 32s 474ms/step - loss: 0.3138 - accuracy: 0.8859 - val_loss: 0.2054 - val_accuracy: 0.9036\n",
            "Epoch 4/20\n",
            "67/67 [==============================] - 32s 475ms/step - loss: 0.3158 - accuracy: 0.8788 - val_loss: 0.2350 - val_accuracy: 0.8911\n",
            "Epoch 5/20\n",
            "67/67 [==============================] - 32s 477ms/step - loss: 0.3131 - accuracy: 0.8733 - val_loss: 0.1962 - val_accuracy: 0.9120\n",
            "Epoch 6/20\n",
            "67/67 [==============================] - 32s 476ms/step - loss: 0.3040 - accuracy: 0.8774 - val_loss: 0.1801 - val_accuracy: 0.9218\n",
            "Epoch 7/20\n",
            "67/67 [==============================] - 32s 478ms/step - loss: 0.3067 - accuracy: 0.8957 - val_loss: 0.2216 - val_accuracy: 0.9092\n",
            "Epoch 8/20\n",
            "67/67 [==============================] - 32s 480ms/step - loss: 0.2584 - accuracy: 0.8934 - val_loss: 0.1856 - val_accuracy: 0.9246\n",
            "Epoch 9/20\n",
            "67/67 [==============================] - 32s 481ms/step - loss: 0.2722 - accuracy: 0.8941 - val_loss: 0.2264 - val_accuracy: 0.9064\n",
            "Epoch 10/20\n",
            "67/67 [==============================] - 32s 477ms/step - loss: 0.2997 - accuracy: 0.8822 - val_loss: 37.7493 - val_accuracy: 0.1830\n",
            "Epoch 11/20\n",
            "67/67 [==============================] - 32s 478ms/step - loss: 0.3182 - accuracy: 0.8623 - val_loss: 9.0571 - val_accuracy: 0.2682\n",
            "Epoch 12/20\n",
            "67/67 [==============================] - 32s 476ms/step - loss: 0.3013 - accuracy: 0.8842 - val_loss: 1.1175 - val_accuracy: 0.6746\n",
            "Epoch 13/20\n",
            "67/67 [==============================] - 32s 476ms/step - loss: 0.3312 - accuracy: 0.8725 - val_loss: 0.2131 - val_accuracy: 0.9190\n",
            "Epoch 14/20\n",
            "67/67 [==============================] - 32s 478ms/step - loss: 0.2809 - accuracy: 0.8770 - val_loss: 0.2125 - val_accuracy: 0.9134\n",
            "Epoch 15/20\n",
            "67/67 [==============================] - 32s 476ms/step - loss: 0.2649 - accuracy: 0.8900 - val_loss: 0.1662 - val_accuracy: 0.9232\n",
            "Epoch 16/20\n",
            "67/67 [==============================] - 32s 479ms/step - loss: 0.2974 - accuracy: 0.8854 - val_loss: 0.1846 - val_accuracy: 0.9176\n",
            "Epoch 17/20\n",
            "67/67 [==============================] - 32s 475ms/step - loss: 0.2486 - accuracy: 0.9057 - val_loss: 1.3872 - val_accuracy: 0.6089\n",
            "Epoch 18/20\n",
            "67/67 [==============================] - 32s 473ms/step - loss: 0.3082 - accuracy: 0.8802 - val_loss: 0.2735 - val_accuracy: 0.8925\n",
            "Epoch 19/20\n",
            "67/67 [==============================] - 32s 475ms/step - loss: 0.2645 - accuracy: 0.8897 - val_loss: 0.1957 - val_accuracy: 0.9190\n",
            "Epoch 20/20\n",
            "67/67 [==============================] - 32s 475ms/step - loss: 0.2639 - accuracy: 0.9006 - val_loss: 0.1762 - val_accuracy: 0.9288\n",
            "loss\n",
            "accuracy\n",
            "val_loss\n",
            "val_accuracy\n",
            "[INFO] evaluating after fine-tuning...\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   brain_normal       0.79      0.79      0.79        19\n",
            "   brain_tumour       0.88      0.97      0.92        31\n",
            "  breast_cancer       0.66      0.88      0.75        56\n",
            "  breast_normal       0.96      0.87      0.92       199\n",
            "cervical_cancer       1.00      1.00      1.00        57\n",
            "cervical_normal       1.00      1.00      1.00        52\n",
            "         ignore       0.99      0.99      0.99        87\n",
            "    lung_cancer       1.00      0.94      0.97        87\n",
            "    lung_normal       0.94      1.00      0.97        83\n",
            " thyroid_cancer       0.95      0.73      0.83        26\n",
            " thyroid_normal       0.82      0.95      0.88        19\n",
            "\n",
            "       accuracy                           0.93       716\n",
            "      macro avg       0.91      0.92      0.91       716\n",
            "   weighted avg       0.94      0.93      0.93       716\n",
            "\n",
            "[INFO] serializing model...\n",
            "INFO:tensorflow:Assets written to: output.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KO8bVmryBO6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faAjNBudyAqx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOTpQIwrjNBt",
        "outputId": "db5b3144-5cc4-4322-ba18-733e140dee85"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install flask_cors\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting flask_cors\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.7/dist-packages (from flask_cors) (1.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask_cors) (1.15.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (2.11.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.9->flask_cors) (1.1.1)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-3.0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg6ZhzemUAyj",
        "outputId": "7c7c4521-d829-4243-9739-9f318fc0eb68"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "from flask import Flask, app,request\n",
        "from base64 import b64decode\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "from imutils import paths\n",
        "import base64\n",
        "import numpy as np\n",
        "import numpy\n",
        "import sys\n",
        "from flask import jsonify\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "import requests\n",
        "import pickle\n",
        "from imutils.video import VideoStream\n",
        "from imutils import paths\n",
        "from threading import Thread\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "from base64 import b64decode\n",
        "import base64\n",
        "import io\n",
        "from flask_cors import CORS, cross_origin\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "cors = CORS(app)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "@app.route('/penta', methods=['GET','POST'])\n",
        "# @cross_origin()\n",
        "def login():\n",
        "    # if request.method == 'POST':\n",
        "    #   # print(\"called\")\n",
        "    result = input(request.json['uri'])\n",
        "    print(\"sfvnvjknb\")\n",
        "    return result\n",
        "    # print(request.json)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def input(uri):\n",
        "    print(\"[INFO] loading model...\")\n",
        "    model = load_model(str(\"drive/MyDrive/20e.model\"))\n",
        "    imagePaths = list(paths.list_images(\"drive/MyDrive/penta_dataset/\"))\n",
        "    classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
        "    classNames = [str(x) for x in np.unique(classNames)]\n",
        "    uri = uri\n",
        "    header, encoded = uri.split(\",\", 1)\n",
        "    data = b64decode(encoded)\n",
        "    f = open(\"uriimage.png\", \"wb\")\n",
        "    f.write(data)\n",
        "    frame = cv2.imread(\"uriimage.png\")\n",
        "    timestamp = datetime.now()\n",
        "    frame = imutils.resize(frame, width=400)\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    roi = cv2.resize(frame, (224, 224))\n",
        "    roi = roi.astype(\"float\") / 255.0\n",
        "    roi = img_to_array(roi)\n",
        "    roi = np.expand_dims(roi, axis=0)\n",
        "    proba = model.predict(roi)[0]\n",
        "    label = classNames[proba.argmax()]\n",
        "    print(label)\n",
        "    return ({\"data\":label})\n",
        "    # if the `q` key was pressed, break from the loop\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://a877f0b91636.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:09] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc663c03320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:13] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "brain_tumour\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:21] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6b5356ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:24] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "brain_tumour\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:41] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc66815b8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:43] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "brain_tumour\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:53] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc668153680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:55:56] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "brain_tumour\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:56:05] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6636ec9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:56:08] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "brain_tumour\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:56:22] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6a01bc8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:56:24] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_normal\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:56:39] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc663a8f830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:56:42] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_normal\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:57:50] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6a01bcf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:57:52] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_normal\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:58:32] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc663a98560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:58:34] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_cancer\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:59:32] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc65663e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 15:59:35] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_cancer\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:00:34] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6a0504680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:00:36] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_cancer\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:01:30] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6a02683b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:01:33] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_cancer\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:01:43] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6681503b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:01:46] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_normal\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:02:39] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6a008ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:02:42] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_normal\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:03:31] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc663add200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:03:33] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_normal\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:04:21] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6a01a0c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:04:24] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_cancer\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:05:14] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6681afb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:05:17] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "breast_normal\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:06:05] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6635e3560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:06:07] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cervical_cancer\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:06:16] \"\u001b[37mOPTIONS /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6632e7680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 16:06:19] \"\u001b[37mPOST /penta HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cervical_cancer\n",
            "sfvnvjknb\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}